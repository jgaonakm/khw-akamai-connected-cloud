# Creating the certificates

In this lab we'll generate the certificates required by our cluster. You can refer to [the documentation](https://kubernetes.io/docs/setup/best-practices/certificates/#how-certificates-are-used-by-your-cluster) to learn how certificates are used.

These are the certificates we need for our excercise:


|                    | Client                         | Server   |
| ------------------ | ------------------------------ | -------- |
| kubelet            | Authenticate to the API Server | Endpoint |
| kube-proxy         | Authenticate to the API Server |
| Controller manager | Talk to API Server             |          |
| Scheduler          | Talk to API Server             |          |
| API Server         | Talk to kubelet                | Endpoint |
|                    | Talk to etcd                   |          |
| Administrators     | Authenticate to the API Server |          |

> ðŸ’¡ For simplicity, and in line with the original tutorial, we'll be generating a single certificate for kubelet, used by both client and server. The same will happen for the API server certificate. Alternatively, we could generate separate client and server certificates.


> ðŸ“— __From the docs__: All Kubernetes components that use these certificates - kubelet, kube-apiserver, kube-controller-manager - assume the key and certificate to be PEM-encoded.


## Certificate Authority

Here we provision a certificate authority to generate the certificates required by the cluster. 



```sh
openssl req -x509 -new -newkey rsa:2048 \
            -verbose \
            -nodes \
            -days 1825 \
            -subj '/CN=ACC Kube CA/C=MX/ST=Jalisco/L=Guadalajara/O=ACC/OU=CA' \
            -addext "basicConstraints=critical,CA:TRUE, pathlen:0" \
            -addext "keyUsage=cRLSign,digitalSignature,keyCertSign" \
            -keyform PEM \
            -keyout ca-key.pem \
            -out ca.pem \
            -outform PEM
```

> ðŸ’¡ In the original guide, 5 years is the default expiry for the CA

Result:

> ca-key.pem
> 
> ca.pem

## Worker Nodes

In this section we generate the certificates and private keys for the worker node components: kubelet and kube-proxy.

### Kubelet client/server certificates

Nodes [communicate with the control plane](https://kubernetes.io/docs/concepts/architecture/control-plane-node-communication/#node-to-control-plane) using the API Server; no other CP component expose remote services (i.e. etcd, controller & scheduler). Kubelets rely on a special-purpose authorization mode, called [node authorization](https://kubernetes.io/docs/reference/access-authn-authz/node/), to authorize API requests made by Kubelets. 


> ðŸ“— __From the docs__: In order to be authorized by the Node authorizer, kubelets must use a credential that identifies them as being in the system:nodes group, with a username of `system:node:\<nodeName>`. This group and user name format match the identity created for each kubelet as part of kubelet TLS bootstrapping.

We generate the certificate for each node, supporting both client and server authentication:

```sh
for i in 0 1 2; do 
INSTANCE="khw-wn${i}"
EXTERNAL_IP=$(lin linodes ls --format label,ipv4 --text --delimiter ' ' | grep ${INSTANCE} | cut -f 2 -d ' ')
echo ${INSTANCE},$EXTERNAL_IP
openssl req -x509 -new -newkey rsa:2048 \
            -verbose \
            -nodes \
            -days 365 \
            -subj "/CN=system:node:${INSTANCE}/O=system:nodes/OU=KHW/C=MX/ST=Jalisco/L=Guadalajara" \
            -addext "keyUsage=critical,digitalSignature,keyEncipherment" \
            -addext "extendedKeyUsage=clientAuth,serverAuth" \
            -addext "basicConstraints=critical,CA:FALSE" \
            -addext "subjectAltName = DNS:${INSTANCE},IP.1:${EXTERNAL_IP},IP.2:10.240.0.2${i}" \
            -CA ca.pem \
            -CAkey ca-key.pem \
            -keyout ${INSTANCE}-key.pem \
            -keyform PEM \
            -out ${INSTANCE}.pem \
            -outform PEM

done
```

Result:

> khw-wn0-key.pem
> 
> khw-wn0.pem
> 
> khw-wn1-key.pem
> 
> khw-wn1.pem
> 
> khw-wn2-key.pem
> 
> khw-wn2.pem

Optionally, but recommended to ensure everything looks OK, check the certificate content:

```sh
# test expiry date
cat [certfile] | openssl x509 -noout -enddate

# show content
$ openssl x509 -in [certfile] -text
```

> ðŸ’¡ In the original guide, all the certificates have a duration of one year


### Kube-proxy client certificate

When `kube-proxy` is installed directly in the node (i.e. not containerized) it requires a separately generated TLS ceritficate to be able to communicate with the API server.

```sh
openssl req -x509 -new -newkey rsa:2048 \
            -days 365 \
            -verbose \
            -nodes \
            -subj '/CN=system:kube-proxy/O=system:node-proxier/OU=KHW/C=MX/ST=Jalisco/L=Guadalajara' \
            -addext "keyUsage=critical,digitalSignature" \
            -addext "extendedKeyUsage=clientAuth" \
            -addext "basicConstraints=critical,CA:FALSE" \
            -CA ca.pem \
            -CAkey ca-key.pem \
            -keyout kube-proxy-key.pem \
            -keyform PEM \
            -out kube-proxy.pem \
            -outform PEM
```

Result

> kube-proxy-key.pem
> 
> kube-proxy.pem


### Distribute certificates

Once we have our certificates, we can distribute them to the worker nodes:

```sh
for i in 0 1 2; do
  INSTANCE="khw-wn${i}"
  EXTERNAL_IP=$(lin linodes ls --format label,ipv4 --text --delimiter ' ' | grep ${INSTANCE} | cut -f 2 -d ' ')
  echo ${INSTANCE},$EXTERNAL_IP
  scp  -i ~/.ssh/[key] ca.pem ${INSTANCE}-key.pem ${INSTANCE}.pem  root@${EXTERNAL_IP}:~
done
```

> ðŸ’¡ The kube-proxy certificate is used to generate config files, hence no need to send it to the worker nodes.



## Control Plane

We now generate the certificates for the control plane components. Both the controller manager and scheduler only talk to the API Server directly, requiring a client certificate. 

### Controller-manager client certificate

```sh
openssl req -x509 -new -newkey rsa:2048 \
            -days 365 \
            -verbose \
            -nodes \
            -subj '/CN=system:kube-controller-manager/O=system:kube-controller-manager/OU=KHW/C=MX/ST=Jalisco/L=Guadalajara' \
            -addext "keyUsage=critical,digitalSignature" \
            -addext "extendedKeyUsage=clientAuth" \
            -addext "basicConstraints=critical,CA:FALSE" \
            -CA ca.pem \
            -CAkey ca-key.pem \
            -keyout kube-controller-manager-key.pem \
            -keyform PEM \
            -out kube-controller-manager.pem \
            -outform PEM
```
Result:

> kube-controller-manager-key.pem
> 
> kube-controller-manager.pem

### Scheduler client certificate

```sh
openssl req -x509 -new -newkey rsa:2048 \
            -days 365 \
            -verbose \
            -nodes \
            -subj '/CN=system:kube-scheduler/O=system:kube-scheduler/OU=KHW/C=MX/ST=Jalisco/L=Guadalajara' \
            -addext "keyUsage=critical,digitalSignature" \
            -addext "extendedKeyUsage=clientAuth" \
            -addext "basicConstraints=critical,CA:FALSE" \
            -CA ca.pem \
            -CAkey ca-key.pem \
            -keyout kube-scheduler-key.pem \
            -keyform PEM \
            -out kube-scheduler.pem \
            -outform PEM
```

Result:

> kube-scheduler-key.pem
> 
> kube-scheduler.pem

### API Server 

As mentioned before, the API server certificate is also used for client authentication (when talking to the `kubelet` and `etc`). We include the NodeBalancer public IP we generated earlier, so we can validate remote requests. 

We'll use the NodeBalancer public address [we generated before](1.instances.md). You can copy it from the [CloudManager](https://cloud.linode.com/nodebalancers) or get it using the CLI:

```sh
KUBERNETES_PUBLIC_ADDRESS=$(linode nodebalancers ls --format label,ipv4 --text --delimiter ' ' | grep khw | cut -f 2 -d ' ')
```

For a cleaner certificate creation command, we set all the values on environment variables first:

```sh
KUBERNETES_HOSTNAMES=DNS.1:kubernetes,DNS.2:kubernetes.default,DNS.3:kubernetes.default.svc,DNS.4:kubernetes.default.svc.cluster,DNS.5:kubernetes.svc.cluster.local
MASTER_CLUSTER_IP=IP.1:10.32.0.1
ETCD_IPS="IP.2:10.240.0.10,IP.3:10.240.0.11,IP.4:10.240.0.12"
SUBJ_ALTNAME="${KUBERNETES_HOSTNAMES},${MASTER_CLUSTER_IP},${ETCD_IPS},IP.5:${KUBERNETES_PUBLIC_ADDRESS},IP.6:127.0.0.1"
```

> ðŸ’¡ MASTER_CLUSTER_IP is usually the first IP from the service CIDR that is specified as the --service-cluster-ip-range argument for both the API server and the controller manager component. We'll set up this range later in the process.

> ðŸ’¡ ETCD_IPS are the private IP addresses we defined for our CP instances, which is used by ETC


```sh
openssl req -x509 -new -newkey rsa:2048 \
            -verbose \
            -nodes \
            -days 365 \
            -subj '/CN=kubernetes/O=Kubernetes/OU=KHW/C=MX/ST=Jalisco/L=Guadalajara' \
            -addext "keyUsage=critical,digitalSignature,keyEncipherment" \
            -addext "extendedKeyUsage=clientAuth,serverAuth" \
            -addext "basicConstraints=critical,CA:FALSE" \
            -addext "subjectAltName = ${SUBJ_ALTNAME}" \
            -CA ca.pem \
            -CAkey ca-key.pem \
            -keyout kubernetes-key.pem \
            -keyform PEM \
            -out kubernetes.pem \
            -outform PEM
```

Result: 

> kubernetes-key.pem
> 
> kubernetes.pem

### Service account key pair

We also need to generate a service account key pair, which is used by the controller manager to sign service account tokens, and by the API server to verify them.

```sh
openssl req -x509 -new -newkey rsa:2048 \
            -verbose \
            -nodes \
            -days 365 \
            -subj '/CN=service-accounts/O=Kubernetes/OU=KHW/C=MX/ST=Jalisco/L=Guadalajara' \
            -addext "keyUsage=critical,digitalSignature" \
            -addext "basicConstraints=critical,CA:FALSE" \
            -CA ca.pem \
            -CAkey ca-key.pem \
            -keyout service-account-key.pem \
            -keyform PEM \
            -out service-account.pem \
            -outform PEM
```
Result:

> service-account-key.pem 
> 
> service-account.pem 

### Distribute certificates

```sh
for i in 0 1 2; do
  INSTANCE="khw-cp${i}"
  EXTERNAL_IP=$(lin linodes ls --format label,ipv4 --text --delimiter ' ' | grep ${INSTANCE} | cut -f 2 -d ' ')
  echo ${INSTANCE},$EXTERNAL_IP
  scp  -i ~/.ssh/[key] ca.pem ca-key.pem kubernetes-key.pem kubernetes.pem \
    service-account-key.pem service-account.pem root@${EXTERNAL_IP}:~
done
```

> ðŸ’¡ The kube-controller-manager, kube-scheduler are used to generate the config files, hence no need to distribute them.


## Administrator

We also need to generate a client certificate for the [administrator of the cluster](https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles) to authenticate to the API server

```sh
openssl req -x509 -new -newkey rsa:2048 \
            -days 365 \
            -verbose \
            -nodes \
            -subj '/CN=admin/O=system:masters/OU=KHW/C=MX/ST=Jalisco/L=Guadalajara' \
            -addext "keyUsage=critical,digitalSignature" \
            -addext "extendedKeyUsage = clientAuth" \
            -addext "basicConstraints=critical,CA:FALSE" \
            -CA ca.pem \
            -CAkey ca-key.pem \
            -keyout admin-key.pem \
            -keyform PEM \
            -out admin.pem \
            -outform PEM
```

---

Next > [Create the config files](3.configFiles.md)

